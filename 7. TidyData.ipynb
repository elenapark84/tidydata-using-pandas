{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep one Column Fixed\n",
    "#### Data can hve columns that contain values instead of variable. This is usually a convinient format for data collection and presentaion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k\n",
      "0                  Agnostic     27       34       60       81       76\n",
      "1                   Atheist     12       27       37       52       35\n",
      "2                  Buddhist     27       21       30       34       33\n",
      "3                  Catholic    418      617      732      670      638\n",
      "4        Don’t know/refused     15       14       15       11       10\n",
      "5          Evangelical Prot    575      869     1064      982      881\n",
      "6                     Hindu      1        9        7        9       11\n",
      "7   Historically Black Prot    228      244      236      238      197\n",
      "8         Jehovah's Witness     20       27       24       24       21\n",
      "9                    Jewish     19       19       25       25       30\n",
      "10            Mainline Prot    289      495      619      655      651\n",
      "11                   Mormon     29       40       48       51       56\n",
      "12                   Muslim      6        7        9       10        9\n",
      "13                 Orthodox     13       17       23       32       32\n",
      "14          Other Christian      9        7       11       13       13\n",
      "15             Other Faiths     20       33       40       46       49\n",
      "16    Other World Religions      5        2        3        4        2\n",
      "17             Unaffiliated    217      299      374      365      341\n"
     ]
    }
   ],
   "source": [
    "# Below is known as wide data \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pew = pd.read_csv('./pew.csv')\n",
    "print(pew.iloc[:, 0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * wide data can be turned into long tidy data format by unpivot/melt/gather.\n",
    "#### * id_vars is container(list, tuple, ndarray) that represents the variable and will remain as is.\n",
    "#### * value_vars identifies the columns you want to melt down or unpivot. By default, it will melt all colimns not specified in id_vars.\n",
    "#### * var_name is a string for the new column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    religion            variable  value\n",
      "0                   Agnostic               <$10k     27\n",
      "1                    Atheist               <$10k     12\n",
      "2                   Buddhist               <$10k     27\n",
      "3                   Catholic               <$10k    418\n",
      "4         Don’t know/refused               <$10k     15\n",
      "5           Evangelical Prot               <$10k    575\n",
      "6                      Hindu               <$10k      1\n",
      "7    Historically Black Prot               <$10k    228\n",
      "8          Jehovah's Witness               <$10k     20\n",
      "9                     Jewish               <$10k     19\n",
      "10             Mainline Prot               <$10k    289\n",
      "11                    Mormon               <$10k     29\n",
      "12                    Muslim               <$10k      6\n",
      "13                  Orthodox               <$10k     13\n",
      "14           Other Christian               <$10k      9\n",
      "15              Other Faiths               <$10k     20\n",
      "16     Other World Religions               <$10k      5\n",
      "17              Unaffiliated               <$10k    217\n",
      "18                  Agnostic             $10-20k     34\n",
      "19                   Atheist             $10-20k     27\n",
      "20                  Buddhist             $10-20k     21\n",
      "21                  Catholic             $10-20k    617\n",
      "22        Don’t know/refused             $10-20k     14\n",
      "23          Evangelical Prot             $10-20k    869\n",
      "24                     Hindu             $10-20k      9\n",
      "25   Historically Black Prot             $10-20k    244\n",
      "26         Jehovah's Witness             $10-20k     27\n",
      "27                    Jewish             $10-20k     19\n",
      "28             Mainline Prot             $10-20k    495\n",
      "29                    Mormon             $10-20k     40\n",
      "..                       ...                 ...    ...\n",
      "150                    Hindu               >150k     54\n",
      "151  Historically Black Prot               >150k     78\n",
      "152        Jehovah's Witness               >150k      6\n",
      "153                   Jewish               >150k    151\n",
      "154            Mainline Prot               >150k    634\n",
      "155                   Mormon               >150k     42\n",
      "156                   Muslim               >150k      6\n",
      "157                 Orthodox               >150k     46\n",
      "158          Other Christian               >150k     12\n",
      "159             Other Faiths               >150k     41\n",
      "160    Other World Religions               >150k      4\n",
      "161             Unaffiliated               >150k    258\n",
      "162                 Agnostic  Don't know/refused     96\n",
      "163                  Atheist  Don't know/refused     76\n",
      "164                 Buddhist  Don't know/refused     54\n",
      "165                 Catholic  Don't know/refused   1489\n",
      "166       Don’t know/refused  Don't know/refused    116\n",
      "167         Evangelical Prot  Don't know/refused   1529\n",
      "168                    Hindu  Don't know/refused     37\n",
      "169  Historically Black Prot  Don't know/refused    339\n",
      "170        Jehovah's Witness  Don't know/refused     37\n",
      "171                   Jewish  Don't know/refused    162\n",
      "172            Mainline Prot  Don't know/refused   1328\n",
      "173                   Mormon  Don't know/refused     69\n",
      "174                   Muslim  Don't know/refused     22\n",
      "175                 Orthodox  Don't know/refused     73\n",
      "176          Other Christian  Don't know/refused     18\n",
      "177             Other Faiths  Don't know/refused     71\n",
      "178    Other World Religions  Don't know/refused      8\n",
      "179             Unaffiliated  Don't know/refused    597\n",
      "\n",
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# we do not need to specify a value_vars sine we want to pivot here\n",
    "# all the columns expect for the 'religion' column\n",
    "\n",
    "pew_long = pd.melt(pew, id_vars = 'religion')\n",
    "print(pew_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion income  count\n",
      "0            Agnostic  <$10k     27\n",
      "1             Atheist  <$10k     12\n",
      "2            Buddhist  <$10k     27\n",
      "3            Catholic  <$10k    418\n",
      "4  Don’t know/refused  <$10k     15\n",
      "                  religion              income  count\n",
      "175               Orthodox  Don't know/refused     73\n",
      "176        Other Christian  Don't know/refused     18\n",
      "177           Other Faiths  Don't know/refused     71\n",
      "178  Other World Religions  Don't know/refused      8\n",
      "179           Unaffiliated  Don't know/refused    597\n"
     ]
    }
   ],
   "source": [
    "# we can change the defaults so that the columns have specific names.\n",
    "\n",
    "pew_long = pd.melt(pew,\n",
    "                  id_vars = 'religion',\n",
    "                  var_name = 'income',\n",
    "                  value_name = 'count')\n",
    "\n",
    "print(pew_long.head())\n",
    "print(pew_long.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Multiple Columns Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  \n",
      "1  92.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2  68.0  67.0  66.0  57.0  54.0  53.0  51.0  51.0  51.0  \n",
      "3  72.0  69.0  67.0  65.0  55.0  59.0  62.0  61.0  61.0  \n",
      "4  25.0  17.0  17.0  31.0  36.0  49.0  53.0  57.0  64.0  \n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv('./billboard.csv')\n",
    "\n",
    "# look at the first few rows and columns\n",
    "print(billboard.iloc[1:5, 0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n",
      "       year            artist                    track  time date.entered  \\\n",
      "24087  2000       Yankee Grey     Another Nine Minutes  3:10   2000-04-29   \n",
      "24088  2000  Yearwood, Trisha          Real Live Woman  3:55   2000-04-01   \n",
      "24089  2000   Ying Yang Twins  Whistle While You Tw...  4:19   2000-03-18   \n",
      "24090  2000     Zombie Nation            Kernkraft 400  3:30   2000-09-02   \n",
      "24091  2000   matchbox twenty                     Bent  4:12   2000-04-29   \n",
      "\n",
      "       week  rating  \n",
      "24087  wk76     NaN  \n",
      "24088  wk76     NaN  \n",
      "24089  wk76     NaN  \n",
      "24090  wk76     NaN  \n",
      "24091  wk76     NaN  \n"
     ]
    }
   ],
   "source": [
    "billboard_long = pd.melt(\n",
    "    billboard, \n",
    "    id_vars=['year', 'artist', 'track', 'time', 'date.entered'],\n",
    "    var_name = 'week',\n",
    "    value_name = 'rating')\n",
    "\n",
    "print(billboard_long.head())\n",
    "print(billboard_long.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns Contain Multiple Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
       "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
       "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
       "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
       "       'Deaths_Spain', 'Deaths_Mali'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebola = pd.read_csv('./country_timeseries.csv')\n",
    "ebola.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Deaths_Guinea  Deaths_Liberia\n",
      "0    1/5/2015  289        2776.0            NaN         1786.0             NaN\n",
      "1    1/4/2015  288        2775.0            NaN         1781.0             NaN\n",
      "2    1/3/2015  287        2769.0         8166.0         1767.0          3496.0\n",
      "3    1/2/2015  286           NaN         8157.0            NaN          3496.0\n",
      "4  12/31/2014  284        2730.0         8115.0         1739.0          3471.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola.iloc[:5, [0, 1, 2, 3, 10, 11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": [
    "ebola_long = pd.melt(ebola, id_vars = ['Date', 'Day'])\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and Add Columns Individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Cases, Guinea]\n",
      "1    [Cases, Guinea]\n",
      "2    [Cases, Guinea]\n",
      "3    [Cases, Guinea]\n",
      "4    [Cases, Guinea]\n",
      "Name: variable, dtype: object\n",
      "1947    [Deaths, Mali]\n",
      "1948    [Deaths, Mali]\n",
      "1949    [Deaths, Mali]\n",
      "1950    [Deaths, Mali]\n",
      "1951    [Deaths, Mali]\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# get the variable column\n",
    "# access the string method\n",
    "# and split the column based on a delimiter\n",
    "\n",
    "variable_split = ebola_long.variable.str.split('_')\n",
    "print(variable_split[:5])\n",
    "print(variable_split[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# after spliting on the underscore, the values are returned in a list.\n",
    "\n",
    "print(type(variable_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# the first element in the container\n",
    "\n",
    "print(type(variable_split[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the columns need to split into the various pieces. it needs to extract all 0-index for status column\n",
    "# and 1-index for the country column. \n",
    "\n",
    "status_values = variable_split.str.get(0)\n",
    "country_values = variable_split.str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Cases\n",
      "1    Cases\n",
      "2    Cases\n",
      "3    Cases\n",
      "4    Cases\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(status_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1942    Deaths\n",
      "1943    Deaths\n",
      "1944    Deaths\n",
      "1945    Deaths\n",
      "1946    Deaths\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(status_values[:-5].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Guinea\n",
      "1    Guinea\n",
      "2    Guinea\n",
      "3    Guinea\n",
      "4    Guinea\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(country_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1942    Mali\n",
      "1943    Mali\n",
      "1944    Mali\n",
      "1945    Mali\n",
      "1946    Mali\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(country_values[:-5].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "# now you have the vectors you want, you can add them to the dataframe\n",
    "\n",
    "ebola_long['status'] = status_values\n",
    "ebola_long['country'] = country_values\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and Combine in a Single Step (simplet method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>status</th>\n",
       "      <th>country</th>\n",
       "      <th>status</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>289</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2015</td>\n",
       "      <td>288</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2775.0</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/2015</td>\n",
       "      <td>287</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>286</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>284</td>\n",
       "      <td>Cases_Guinea</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "      <td>Cases</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Day      variable   value status country status country\n",
       "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea  Cases  Guinea\n",
       "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea  Cases  Guinea\n",
       "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea  Cases  Guinea\n",
       "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea  Cases  Guinea\n",
       "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea  Cases  Guinea"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_split = ebola_long.variable.str.split('_', expand=True)\n",
    "variable_split.columns = ['status', 'country']\n",
    "ebola_parsed = pd.concat([ebola_long, variable_split], axis=1)\n",
    "\n",
    "ebola_parsed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and Combine in a Single Step (more complicated method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pi', '3.14'), ('e', '2.718')]\n"
     ]
    }
   ],
   "source": [
    "constants = ['pi', 'e']\n",
    "values = ['3.14', '2.718']\n",
    "\n",
    "# we have to call list on the zip function to show the contents of the zip object\n",
    "# in python3, zip returns an interator\n",
    "\n",
    "print(list(zip(constants,  values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "ebola_long['status'], ebola_long['country'] = \\\n",
    "    zip(*ebola_long.variable.str.split('_'))\n",
    "\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables in Both Rows and Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element  d1    d2    d3  d4    d5  d6  d7\n",
      "0  MX17004  2010      1    tmax NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "1  MX17004  2010      1    tmin NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "2  MX17004  2010      2    tmax NaN  27.3  24.1 NaN   NaN NaN NaN\n",
      "3  MX17004  2010      2    tmin NaN  14.4  14.4 NaN   NaN NaN NaN\n",
      "4  MX17004  2010      3    tmax NaN   NaN   NaN NaN  32.1 NaN NaN\n"
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv('./weather.csv')\n",
    "print(weather.iloc[:5, :11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element day  temp\n",
      "0  MX17004  2010      1    tmax  d1   NaN\n",
      "1  MX17004  2010      1    tmin  d1   NaN\n",
      "2  MX17004  2010      2    tmax  d1   NaN\n",
      "3  MX17004  2010      2    tmin  d1   NaN\n",
      "4  MX17004  2010      3    tmax  d1   NaN\n",
      "          id  year  month element  day  temp\n",
      "677  MX17004  2010     10    tmin  d31   NaN\n",
      "678  MX17004  2010     11    tmax  d31   NaN\n",
      "679  MX17004  2010     11    tmin  d31   NaN\n",
      "680  MX17004  2010     12    tmax  d31   NaN\n",
      "681  MX17004  2010     12    tmin  d31   NaN\n"
     ]
    }
   ],
   "source": [
    "weather_melt= pd.melt(weather, id_vars = ['id', 'year', 'month', 'element'],\n",
    "                      var_name = 'day', value_name = 'temp'\n",
    "                     )\n",
    "print(weather_melt.head())\n",
    "print(weather_melt.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>element</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"33\" valign=\"top\">MX17004</th>\n",
       "      <th rowspan=\"33\" valign=\"top\">2010</th>\n",
       "      <th>1</th>\n",
       "      <th>d30</th>\n",
       "      <td>27.8</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>d11</th>\n",
       "      <td>29.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2</th>\n",
       "      <td>27.3</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d23</th>\n",
       "      <td>29.9</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3</th>\n",
       "      <td>24.1</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>d10</th>\n",
       "      <td>34.5</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d16</th>\n",
       "      <td>31.1</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5</th>\n",
       "      <td>32.1</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>d27</th>\n",
       "      <td>36.3</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>d27</th>\n",
       "      <td>33.2</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>d17</th>\n",
       "      <td>28.0</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d29</th>\n",
       "      <td>30.1</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>d3</th>\n",
       "      <td>28.6</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>29.9</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">8</th>\n",
       "      <th>d23</th>\n",
       "      <td>26.4</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5</th>\n",
       "      <td>29.6</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d29</th>\n",
       "      <td>28.0</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d13</th>\n",
       "      <td>29.8</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d25</th>\n",
       "      <td>29.7</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d31</th>\n",
       "      <td>25.4</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d8</th>\n",
       "      <td>29.0</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10</th>\n",
       "      <th>d5</th>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d14</th>\n",
       "      <td>29.5</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d15</th>\n",
       "      <td>28.7</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d28</th>\n",
       "      <td>31.2</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d7</th>\n",
       "      <td>28.1</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">11</th>\n",
       "      <th>d2</th>\n",
       "      <td>31.3</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5</th>\n",
       "      <td>26.3</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d27</th>\n",
       "      <td>27.7</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d26</th>\n",
       "      <td>28.1</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d4</th>\n",
       "      <td>27.2</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">12</th>\n",
       "      <th>d1</th>\n",
       "      <td>29.9</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6</th>\n",
       "      <td>27.8</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "element                 tmax  tmin\n",
       "id      year month day            \n",
       "MX17004 2010 1     d30  27.8  14.5\n",
       "             2     d11  29.7  13.4\n",
       "                   d2   27.3  14.4\n",
       "                   d23  29.9  10.7\n",
       "                   d3   24.1  14.4\n",
       "             3     d10  34.5  16.8\n",
       "                   d16  31.1  17.6\n",
       "                   d5   32.1  14.2\n",
       "             4     d27  36.3  16.7\n",
       "             5     d27  33.2  18.2\n",
       "             6     d17  28.0  17.5\n",
       "                   d29  30.1  18.0\n",
       "             7     d3   28.6  17.5\n",
       "                   d14  29.9  16.5\n",
       "             8     d23  26.4  15.0\n",
       "                   d5   29.6  15.8\n",
       "                   d29  28.0  15.3\n",
       "                   d13  29.8  16.5\n",
       "                   d25  29.7  15.6\n",
       "                   d31  25.4  15.4\n",
       "                   d8   29.0  17.3\n",
       "             10    d5   27.0  14.0\n",
       "                   d14  29.5  13.0\n",
       "                   d15  28.7  10.5\n",
       "                   d28  31.2  15.0\n",
       "                   d7   28.1  12.9\n",
       "             11    d2   31.3  16.3\n",
       "                   d5   26.3   7.9\n",
       "                   d27  27.7  14.2\n",
       "                   d26  28.1  12.1\n",
       "                   d4   27.2  12.0\n",
       "             12    d1   29.9  13.8\n",
       "                   d6   27.8  10.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to pivot up the variables stored in the element column.\n",
    "\n",
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index = ['id', 'year', 'month', 'day'],\n",
    "    columns = 'element',\n",
    "    values = 'temp')\n",
    "\n",
    "weather_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year  month  day  tmax  tmin\n",
      "0        MX17004  2010      1  d30  27.8  14.5\n",
      "1        MX17004  2010      2  d11  29.7  13.4\n",
      "2        MX17004  2010      2   d2  27.3  14.4\n",
      "3        MX17004  2010      2  d23  29.9  10.7\n",
      "4        MX17004  2010      2   d3  24.1  14.4\n"
     ]
    }
   ],
   "source": [
    "weather_tidy_flat = weather_tidy.reset_index()\n",
    "print(weather_tidy_flat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year  month  day  tmax  tmin\n",
      "0        MX17004  2010      1  d30  27.8  14.5\n",
      "1        MX17004  2010      2  d11  29.7  13.4\n",
      "2        MX17004  2010      2   d2  27.3  14.4\n",
      "3        MX17004  2010      2  d23  29.9  10.7\n",
      "4        MX17004  2010      2   d3  24.1  14.4\n"
     ]
    }
   ],
   "source": [
    "weather_tidy = weather_melt.\\\n",
    "    pivot_table(\n",
    "        index = ['id', 'year', 'month', 'day'],\n",
    "        columns = 'element',\n",
    "        values = 'temp').\\\n",
    "    reset_index()\n",
    "\n",
    "print(weather_tidy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Observational Unit in a Table (Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year        artist  track  time date.entered week  rating\n",
      "3     2000  3 Doors Down  Loser  4:24   2000-10-21  wk1    76.0\n",
      "320   2000  3 Doors Down  Loser  4:24   2000-10-21  wk2    76.0\n",
      "637   2000  3 Doors Down  Loser  4:24   2000-10-21  wk3    72.0\n",
      "954   2000  3 Doors Down  Loser  4:24   2000-10-21  wk4    69.0\n",
      "1271  2000  3 Doors Down  Loser  4:24   2000-10-21  wk5    67.0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_long[billboard_long.track == 'Loser'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 4)\n"
     ]
    }
   ],
   "source": [
    "billboard_songs = billboard_long[['year', 'artist', 'track', 'time']]\n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 4)\n"
     ]
    }
   ],
   "source": [
    "billboard_songs = billboard_songs.drop_duplicates()\n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year          artist                    track  time  id\n",
      "0  2000           2 Pac  Baby Don't Cry (Keep...  4:22   0\n",
      "1  2000         2Ge+her  The Hardest Part Of ...  3:15   1\n",
      "2  2000    3 Doors Down               Kryptonite  3:53   2\n",
      "3  2000    3 Doors Down                    Loser  4:24   3\n",
      "4  2000        504 Boyz            Wobble Wobble  3:35   4\n",
      "5  2000            98^0  Give Me Just One Nig...  3:24   5\n",
      "6  2000         A*Teens            Dancing Queen  3:44   6\n",
      "7  2000         Aaliyah            I Don't Wanna  4:15   7\n",
      "8  2000         Aaliyah                Try Again  4:03   8\n",
      "9  2000  Adams, Yolanda            Open My Heart  5:30   9\n"
     ]
    }
   ],
   "source": [
    "billboard_songs['id'] = range(len(billboard_songs))\n",
    "print(billboard_songs.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 8)\n"
     ]
    }
   ],
   "source": [
    "# merge the song dataframe to the original data set\n",
    "\n",
    "billboard_ratings = billboard_long.merge(billboard_songs, on=['year', 'artist', 'track', 'time'])\n",
    "print(billboard_ratings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year artist                    track  time date.entered week  rating  id\n",
      "0  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0   0\n",
      "1  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk2    82.0   0\n",
      "2  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk3    72.0   0\n",
      "3  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk4    77.0   0\n",
      "4  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk5    87.0   0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observational Units Across Multiple Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-01.csv\n",
      "\n",
      "../data/fhv_tripdata_2015-01.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-02.csv\n",
      "\n",
      "../data/fhv_tripdata_2015-02.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-03.csv\n",
      "\n",
      "../data/fhv_tripdata_2015-03.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-04.csv\n",
      "\n",
      "../data/fhv_tripdata_2015-04.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-05.csv\n",
      "\n",
      "../data/fhv_tripdata_2015-05.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "# code to download the \n",
    "# download only the first 5 data sets from the list of files\n",
    "\n",
    "with open('./raw_data_urls.txt', 'r') as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5 :\n",
    "            break\n",
    "        fn = url.split('/') [-1].strip()\n",
    "        fp = os.path.join('..', 'data', fn)\n",
    "        print(url)\n",
    "        print(fp)\n",
    "        urllib.request.urlretrieve(url, fp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./fhv_tripdata_2015-05.csv', './fhv_tripdata_2015-04.csv', './fhv_tripdata_2015-01.csv', './fhv_tripdata_2015-03.csv', './fhv_tripdata_2015-02.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "# get a list of the csv files from the nyc-taxi data folder\n",
    "\n",
    "nyc_taxi_data = glob.glob('./fhv_*')\n",
    "print(nyc_taxi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each file into a dataframe\n",
    "\n",
    "taxi1 = pd.read_csv(nyc_taxi_data[0])\n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1])\n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2])\n",
    "taxi4 = pd.read_csv(nyc_taxi_data[3])\n",
    "taxi5 = pd.read_csv(nyc_taxi_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-05-01 04:30:00         NaN\n",
      "1               B00001  2015-05-01 05:00:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-04-01 04:30:00         NaN\n",
      "1               B00001  2015-04-01 06:00:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-01-01 00:30:00         NaN\n",
      "1               B00013  2015-01-01 01:22:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00029  2015-03-01 00:02:00       213.0\n",
      "1               B00029  2015-03-01 00:03:00        51.0\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-02-01 00:00:00         NaN\n",
      "1               B00013  2015-02-01 00:01:00         NaN\n"
     ]
    }
   ],
   "source": [
    "print(taxi1.head(n=2))\n",
    "print(taxi2.head(n=2))\n",
    "print(taxi3.head(n=2))\n",
    "print(taxi4.head(n=2))\n",
    "print(taxi5.head(n=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4296067, 3)\n",
      "(3917789, 3)\n",
      "(2746033, 3)\n",
      "(3281427, 3)\n",
      "(3126401, 3)\n"
     ]
    }
   ],
   "source": [
    "print(taxi1.shape)\n",
    "print(taxi2.shape)\n",
    "print(taxi3.shape)\n",
    "print(taxi4.shape)\n",
    "print(taxi5.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17367717, 3)\n"
     ]
    }
   ],
   "source": [
    "taxi = pd.concat([taxi1, taxi2, taxi3, taxi4, taxi5])\n",
    "print(taxi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Multiple Files Using a Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to append to \n",
    "\n",
    "list_taxi_df = []\n",
    "\n",
    "# loop through each CSV file name\n",
    "\n",
    "for csv_filename in nyc_taxi_data:\n",
    "    # you can choose to print the filename for debugging\n",
    "    # print(csv_filename)\n",
    "    \n",
    "    #load the csv file into a dataframe\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    \n",
    "    # append the dataframe to the list that will hold the dataframes\n",
    "    list_taxi_df.append(df)\n",
    "    \n",
    "#print the length of the dataframe\n",
    "print(len(list_taxi_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# type of the first element\n",
    "print(type(list_taxi_df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-05-01 04:30:00         NaN\n",
      "1               B00001  2015-05-01 05:00:00         NaN\n",
      "2               B00001  2015-05-01 05:05:00         NaN\n",
      "3               B00001  2015-05-01 06:15:00         NaN\n",
      "4               B00001  2015-05-01 06:15:00         NaN\n"
     ]
    }
   ],
   "source": [
    "# look at the head of the first dataframe\n",
    "print(list_taxi_df[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17367717, 3)\n"
     ]
    }
   ],
   "source": [
    "taxi_loop_concat = pd.concat(list_taxi_df)\n",
    "print(taxi_loop_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(taxi.equals(taxi_loop_concat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Multiple Files Using a List Comprehension\n",
    "#### Python has an idiom for looping through something and adding it to a list, called a list comprehension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# the loop code without comments\n",
    "list_taxi_df = []\n",
    "for csv_filename in nyc_taxi_data:\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    list_taxi_df.append(df)\n",
    "    \n",
    "\n",
    "# same code in a list comprehension\n",
    "list_taxi_df_comp = [pd.read_csv(data) for data in nyc_taxi_data]\n",
    "print(type(list_taxi_df_comp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# now you can concatenate the results\n",
    "taxi_loop_cancat_comp = pd.concat(list_taxi_df_comp)\n",
    "\n",
    "# are the concatenated dataframes the same?\n",
    "print(taxi_loop_cancat_comp.equals(taxi_loop_concat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
